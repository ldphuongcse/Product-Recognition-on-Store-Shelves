{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step A - Multiple Product Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Matching(Model_Descriptors, Scene_Descriptors, Treshold = 0.45, k=2):\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "\n",
    "        # Defining parameters for algorithm \n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "\n",
    "        # Defining search params.\n",
    "        # checks=50 specifies the number of times the trees in the index should be recursively traversed.\n",
    "        # Higher values gives better precision, but also takes more time\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "        # Initializing matcher\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        # Matching and finding the 2 closest elements for each query descriptor.\n",
    "    matches = flann.knnMatch(Model_Descriptors, Scene_Descriptors, k)\n",
    "        #defining an array containing all the matches that results to be considered \"good\" matches applying a certain treshold \n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < Treshold * n.distance: #  if m.distance/n.distance < Threshold:\n",
    "            good.append(m)\n",
    "            \n",
    "    return good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(e_results, idx_of_scene):\n",
    "    for i in models_to_test:\n",
    "        print('Product {} - {} instance/s found:'.format(i, e_results[idx_of_scene][i]['count']))\n",
    "        n = 0\n",
    "        if e_results[idx_of_scene][i].get('width', None):\n",
    "            n += 1\n",
    "            print('\\tInstance {} position: {}, width: {}px, height: {}px'.format(n, e_results[idx_of_scene][i]['pos'], e_results[idx_of_scene][i]['width'], e_results[idx_of_scene][i]['height']))\n",
    "    print('_' * 80 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_2_points(A, B):\n",
    "    return math.sqrt( np.power(A[0] - B[0], 2) +  np.power(A[1] - B[1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that plots the final merged bounding boxes\n",
    "def plot_final_bounding_boxes(img, final_corners_of_bounding_boxes, difficulty_scenes_images_features, j, thickness=20):\n",
    "    #print('Final corners of bounding boxes:')\n",
    "    #print(final_corners_of_bounding_boxes)\n",
    "    \n",
    "    if img is None:\n",
    "        img = np.copy(difficulty_scenes_images_features[j][IMAGE_INDEX])\n",
    "    #print(img.shape)\n",
    "\n",
    "    \n",
    "    # print final bounding boxes on an image\n",
    "    for top_left_corner, bottom_right_corner in final_corners_of_bounding_boxes:\n",
    "        scene_img_with_FINAL_bounding_boxes = cv2.rectangle(img, top_left_corner, bottom_right_corner, (0,255,0), thickness)\n",
    "\n",
    "    \n",
    "    \n",
    "    # plot image with final bounding boxes (with bounding boxes that do not overlap each other)\n",
    "    if(len(final_corners_of_bounding_boxes) > 0):\n",
    "        #print('  - Found {} instances of model {} in scene {}'.format(len(final_corners_of_bounding_boxes),i,j))\n",
    "        # plotting the bounding box\n",
    "        #plt.imshow(cv2.cvtColor(scene_img_with_FINAL_bounding_boxes, cv2.COLOR_BGR2RGB))\n",
    "        #plt.show()\n",
    "        \n",
    "        return scene_img_with_FINAL_bounding_boxes\n",
    "    else:\n",
    "        #print('  - Model {} NOT found in the scene {}'.format(i,j))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that solves exceeding dimensions of bounding_boxes in scene\n",
    "def solve_exceeding_dimensions_of_bounding_boxes_in_scene(final_corners_of_bounding_boxes, difficulty_scenes_images_features):\n",
    "    final_corners_of_bounding_boxes_without_exceeding_dimensions = []\n",
    "    # adjust bounding boxes that go out the dimensions of the scene image\n",
    "    scene_height = difficulty_scenes_images_features[j][IMAGE_INDEX].shape[0]\n",
    "    scene_width = difficulty_scenes_images_features[j][IMAGE_INDEX].shape[1]\n",
    "\n",
    "    for index, [fin_top_left_corner, fin_bottom_right_corner] in enumerate(final_corners_of_bounding_boxes):\n",
    "        fin_top_left_corner = list(fin_top_left_corner)\n",
    "        fin_bottom_right_corner = list(fin_bottom_right_corner)\n",
    "        # top left corner that goes out on the left of the scene image\n",
    "        if fin_top_left_corner[0] < 0:\n",
    "            fin_top_left_corner[0] = 0\n",
    "        # bottom right corner that goes out on the left of the scene image\n",
    "        if fin_bottom_right_corner[0] < 0:\n",
    "            fin_bottom_right_corner[0] = 0\n",
    "        # top left corner that goes out on the right of the scene image\n",
    "        if fin_top_left_corner[0] > scene_width:\n",
    "            fin_top_left_corner[0] = scene_width\n",
    "        # bottom right corner that goes out on the right of the scene image\n",
    "        if fin_bottom_right_corner[0] > scene_width:\n",
    "            fin_bottom_right_corner[0] = scene_width\n",
    "        # top left corner that goes out on the top of the scene image\n",
    "        if fin_top_left_corner[1] < 0:\n",
    "            fin_top_left_corner[1] = 0\n",
    "        # bottom right corner that goes out on the top of the scene image\n",
    "        if fin_bottom_right_corner[1] < 0:\n",
    "            fin_bottom_right_corner[1] = 0  \n",
    "        # top left corner that goes out on the bottom of the scene image\n",
    "        if fin_top_left_corner[1] > scene_height:\n",
    "            fin_top_left_corner[1] = scene_height\n",
    "        # bottom right corner that goes out on the bottom of the scene image\n",
    "        if fin_bottom_right_corner[1] > scene_height:\n",
    "            fin_bottom_right_corner[1] = scene_height\n",
    "\n",
    "        fin_top_left_corner = tuple(fin_top_left_corner)\n",
    "        fin_bottom_right_corner = tuple(fin_bottom_right_corner)\n",
    "        final_corners_of_bounding_boxes_without_exceeding_dimensions.append([ (int(fin_top_left_corner[0]), \n",
    "                                                                               int(fin_top_left_corner[1])), \n",
    "                                                                             (int(fin_bottom_right_corner[0]), \n",
    "                                                                              int(fin_bottom_right_corner[1]))])\n",
    "    return final_corners_of_bounding_boxes_without_exceeding_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that split an image into (n_bins_heigth x n_bins_width) bins and returns a dictonary\n",
    "# that contains the means of the 3 color channels of the (n_bins_heigth x n_bins_width) bins\n",
    "def split_image_into_N_x_M_bins_with_intensity_means(image, n_bins_width = 3, n_bins_heigth = 4):\n",
    "    img_N_x_M_bins = {}\n",
    "    \n",
    "    img2 = np.copy(image)\n",
    "    \n",
    "    img_width = image.shape[1]\n",
    "    img_height = image.shape[0]\n",
    "    \n",
    "    step_width = int(img_width / n_bins_width)\n",
    "    step_height = int(img_height / n_bins_heigth)\n",
    "    \n",
    "    r = 0\n",
    "    c = 0\n",
    "    \n",
    "    #print('img_height: ', img_height)\n",
    "    #print('step_height: ', step_height)\n",
    "    if img_height != 0 and step_height != 0 and img_width != 0 and step_width != 0:\n",
    "        for row in np.arange(0, img_height, step_height):\n",
    "            c = 0\n",
    "            cv2.line(img2,(0, row),(img_width, row),(0,0,0),3) \n",
    "            for col in np.arange(0, img_width, step_width):\n",
    "                # print('row {} col {}'.format(r,c))\n",
    "                if row + 2 * step_height > img_height and col + 2 * step_width > img_width:\n",
    "                    partial_r_channel, partial_g_channel, partial_b_channel = cv2.split(image[row:, col:])\n",
    "\n",
    "                elif row + 2 * step_height > img_height:\n",
    "                    partial_r_channel, partial_g_channel, partial_b_channel = cv2.split(image[row:, col : col + step_width])\n",
    "\n",
    "                elif col + 2 * step_width > img_width:\n",
    "                    partial_r_channel, partial_g_channel, partial_b_channel = cv2.split(image[row : row + step_height, col :])\n",
    "                else:\n",
    "                    partial_r_channel, partial_g_channel, partial_b_channel = cv2.split(\n",
    "                        image[row : row + step_height, col : col + step_width])\n",
    "\n",
    "                cv2.line(img2,(col, 0),(col, img_height),(0,0,0),3) \n",
    "                if r < n_bins_heigth and c < n_bins_width:\n",
    "                    # save means of the 3 channels (r,g,b) of each bin\n",
    "                    img_N_x_M_bins[r, c] = (np.mean(partial_r_channel), np.mean(partial_g_channel), np.mean(partial_b_channel))\n",
    "                    # IF YOU WANT TO VISUALIZE EACH BIN UNCOMMENT THE FOLLOWING LINES:\n",
    "                    # plot each bin in blue channel color\n",
    "                    # plt.imshow(cv2.cvtColor(partial_b_channel, cv2.COLOR_BGR2RGB))\n",
    "                    # plt.show()\n",
    "\n",
    "                    # salva le medie e non le immagini dei bins\n",
    "\n",
    "                c += 1\n",
    "            r += 1\n",
    "        #plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "        #plt.show()  \n",
    "    return img_N_x_M_bins\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_color_problem_with_N_x_M_bins(final_corners_of_bounding_boxes_without_exceeding_dimensions, \n",
    "                                    difficulty_scenes_images_features, i, j, N=3, M=4, \n",
    "                                    COLOR_DIFF_IN_SINGLE_CHANNEL_TRES=50, MAX_NUM_OF_NO_GOOD_CELLS=2):\n",
    "    final_corners_of_bounding_boxes_after_color_problem = []\n",
    "    for index, [fin_top_left_corner, fin_bottom_right_corner] in enumerate(final_corners_of_bounding_boxes_without_exceeding_dimensions):\n",
    "    \n",
    "        means_bins_model_img = split_image_into_N_x_M_bins_with_intensity_means(\n",
    "            model_images_features[i][IMAGE_INDEX], \n",
    "            N, M)\n",
    "        \n",
    "        #print(fin_top_left_corner[1], fin_top_left_corner[0], fin_bottom_right_corner[1], fin_bottom_right_corner[0])\n",
    "        \n",
    "        means_bins_scene_img = split_image_into_N_x_M_bins_with_intensity_means(\n",
    "            difficulty_scenes_images_features[j][IMAGE_INDEX][fin_top_left_corner[1]:fin_bottom_right_corner[1], \n",
    "                                                                   fin_top_left_corner[0]:fin_bottom_right_corner[0]], \n",
    "            N, M)\n",
    "    \n",
    "        if not means_bins_scene_img or not means_bins_scene_img:\n",
    "            return []\n",
    "    \n",
    "        good = True\n",
    "        num_of_No_good = 0\n",
    "        \n",
    "        \n",
    "        # cycle the model dictionary and get the diff of the means by getting the keys of the scene dictionary\n",
    "        for k, v in means_bins_model_img.items():\n",
    "            means_k_scene = means_bins_scene_img.get(k)\n",
    "            # I consider a bounding box as good if and only if all the difference of the intiensities from the \n",
    "            # bins of the model, in all 3 channels, are below a certain treshold\n",
    "            diff_r = np.absolute(v[0] - means_k_scene[0])\n",
    "            diff_g = np.absolute(v[1] - means_k_scene[1])\n",
    "            diff_b = np.absolute(v[2] - means_k_scene[2])\n",
    "            \n",
    "            #print('Bin ({}, {}):'.format(k[0], k[1]))\n",
    "            #print('  - diff_r: ', diff_r)\n",
    "            #print('  - diff_g: ', diff_g)\n",
    "            #print('  - diff_b: ', diff_b)\n",
    "            \n",
    "            # PRINT ALL THE DIFFERENCES\n",
    "            # print('diff_r: ', diff_r)\n",
    "            # print('diff_g: ', diff_g)\n",
    "            # print('diff_b: ', diff_b)\n",
    "\n",
    "            \n",
    "            if diff_r >= COLOR_DIFF_IN_SINGLE_CHANNEL_TRES or diff_g >= COLOR_DIFF_IN_SINGLE_CHANNEL_TRES or \\\n",
    "                diff_b >= COLOR_DIFF_IN_SINGLE_CHANNEL_TRES:\n",
    "                #print('___________________NO GOOD___________________')\n",
    "                num_of_No_good += 1\n",
    "                good = False\n",
    "            \n",
    "        if num_of_No_good < MAX_NUM_OF_NO_GOOD_CELLS:\n",
    "            final_corners_of_bounding_boxes_after_color_problem.append([ (int(fin_top_left_corner[0]), int(fin_top_left_corner[1])), \n",
    "                                                        (int(fin_bottom_right_corner[0]), int(fin_bottom_right_corner[1]))])\n",
    "            \n",
    "    \n",
    "    return final_corners_of_bounding_boxes_after_color_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_MODELS = 27\n",
    "\n",
    "IMAGE_INDEX      = 0\n",
    "KEYPOINT_INDEX   = 1\n",
    "DESCRIPTOR_INDEX = 2\n",
    "CENTER_INDEX     = 3\n",
    "V_INDEX          = 4\n",
    "TRESHOLD_INDEX = 5\n",
    "\n",
    "# Dictionary that contains the image, all keypoints and descriptors for each model images\n",
    "model_images_features = {}\n",
    "mean_of_model_intensities_r_g_b = {}\n",
    "\n",
    "for i in range(NUM_OF_MODELS):\n",
    "    model_img = cv2.imread('./models/{}.jpg'.format(i), cv2.COLOR_BGR2RGB)\n",
    "    kp_model = sift.detect(model_img)\n",
    "    kp_model, des_model = sift.compute(model_img, kp_model)\n",
    "    model_images_features[i] = [model_img, kp_model, des_model]\n",
    "    \n",
    "    b,g,r = cv2.split(model_images_features[i][IMAGE_INDEX])\n",
    "    # save the mean of the intensities (divided per channel) for every model image\n",
    "    mean_of_model_intensities_r_g_b[i] = [np.mean(r), np.mean(g), np.mean(b)]\n",
    "    # print(mean_of_model_intensities_r_g_b[i][0], mean_of_model_intensities_r_g_b[i][1], mean_of_model_intensities_r_g_b[i][2])\n",
    "    # print(model_images_features[i][IMAGE_INDEX][0].shape)\n",
    "    # print(mean_of_model_intensities[i])\n",
    "\n",
    "    \n",
    "    # plt.imshow(cv2.cvtColor(model_images_features[str(i)][0], cv2.COLOR_BGR2RGB))\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that plots the final merged bounding boxes\n",
    "def plot_dark_area_bounding_boxes(img, final_corners_of_bounding_boxes, difficulty_scenes_images_features, j):\n",
    "    #print('Final corners of bounding boxes:')\n",
    "    #print(final_corners_of_bounding_boxes)\n",
    "    \n",
    "    \n",
    "    # print final bounding boxes on an image\n",
    "    for top_left_corner, bottom_right_corner in final_corners_of_bounding_boxes:\n",
    "        scene_img_with_FINAL_bounding_boxes = cv2.rectangle(img, top_left_corner, bottom_right_corner, (0,0,0), -1)\n",
    "\n",
    "    \n",
    "    \n",
    "    # plot image with final bounding boxes (with bounding boxes that do not overlap each other)\n",
    "    if(len(final_corners_of_bounding_boxes) > 0):\n",
    "        #print('  - Found {} instances of model {} in scene {}'.format(len(final_corners_of_bounding_boxes),i,j))\n",
    "        # plotting the bounding box\n",
    "        #plt.imshow(cv2.cvtColor(scene_img_with_FINAL_bounding_boxes, cv2.COLOR_BGR2RGB))\n",
    "        #plt.show()\n",
    "        \n",
    "        return scene_img_with_FINAL_bounding_boxes\n",
    "    else:\n",
    "        #print('  - Model {} NOT found in the scene {}'.format(i,j))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_to_test = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Dictionary that contains the image, all keypoints and descriptors for each easy scene image\n",
    "e_scenes_images_features = {}\n",
    "\n",
    "for i in scenes_to_test:\n",
    "    scene_img = cv2.imread('./scenes/e{}.png'.format(i), cv2.COLOR_BGR2RGB)\n",
    "    kp_scene = sift.detect(scene_img)\n",
    "    kp_scene, des_scene = sift.compute(scene_img, kp_scene)\n",
    "    e_scenes_images_features[i] = [scene_img, kp_scene, des_scene]\n",
    "    # scene_img_visualization = cv2.drawKeypoints(scene_img,kp_e_scemes_images['1'],None,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # plt.imshow(cv2.cvtColor(e_scenes_images_features[str(i)][0], cv2.COLOR_BGR2RGB))\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary that will contain the output to be printed\n",
    "e_results = {}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_INDEX      = 0\n",
    "KEYPOINT_INDEX   = 1\n",
    "DESCRIPTOR_INDEX = 2\n",
    "\n",
    "models_to_test = [0,1,11, 19, 24, 26, 25] #[1] #, 1, 11, 19, 24, 26, 25] # [0,11,25]\n",
    "scenes_to_test = [1,2,3,4,5] # [2,3,4]\n",
    "MATCHING_TRESHOLD = 0.45\n",
    "\n",
    "MIN_NUM_OF_MATCHES = 15\n",
    "\n",
    "COLOR_DIFF_IN_SINGLE_CHANNEL_TRES = 79\n",
    "\n",
    "N_BINS_ON_WIDTH = 3\n",
    "\n",
    "M_BINS_ON_HEIGHT = 4\n",
    "\n",
    "final_scene_images_with_bb = {}\n",
    "\n",
    "scene_single_model_features = {}\n",
    "\n",
    "MAX_NUM_OF_NO_GOOD_CELLS = 1\n",
    "\n",
    "for j in scenes_to_test:\n",
    "    final_scene_images_with_bb[j] = np.copy(e_scenes_images_features[j][IMAGE_INDEX])\n",
    "    e_results[j] = {}\n",
    "    for i in models_to_test:\n",
    "        scene_single_model = np.copy(e_scenes_images_features[j][IMAGE_INDEX])\n",
    "        #print('_' * 80 + '\\n')\n",
    "        #print('Finding model {} in scene {}'.format(i,j))\n",
    "        \n",
    "        e_results[j][i] = {}\n",
    "        e_results[j][i]['count'] = 0\n",
    "        \n",
    "         # Checking if we found enough matching\n",
    "        MIN_MATCH_COUNT = MIN_NUM_OF_MATCHES\n",
    "        \n",
    "        finding = True\n",
    "        \n",
    "        # If enough matches => the model is in the scene image\n",
    "        while finding:\n",
    "            \n",
    "            kp_scene = sift.detect(scene_single_model)\n",
    "            kp_scene, des_scene = sift.compute(scene_single_model, kp_scene)\n",
    "            scene_single_model_features[j] = [scene_single_model, kp_scene, des_scene]\n",
    "            good = Matching(model_images_features[i][DESCRIPTOR_INDEX], scene_single_model_features[j][DESCRIPTOR_INDEX], \n",
    "                            Treshold = MATCHING_TRESHOLD, k=2)#flann.knnMatch(model_images_features[i][DESCRIPTOR_INDEX], e_scenes_images_features[j][DESCRIPTOR_INDEX], k=2)\n",
    "            good = Matching(model_images_features[i][DESCRIPTOR_INDEX], scene_single_model_features[j][DESCRIPTOR_INDEX], \n",
    "                            Treshold = MATCHING_TRESHOLD, k=2)#flann.knnMatch(model_images_features[i][DESCRIPTOR_INDEX], e_scenes_images_features[j][DESCRIPTOR_INDEX], k=2)\n",
    " \n",
    "            #print(len(good))\n",
    "            \n",
    "            if len(good) < MIN_MATCH_COUNT:\n",
    "                finding = False\n",
    "                \n",
    "            \n",
    "            if len(good) >= MIN_MATCH_COUNT:\n",
    "                \n",
    "                \n",
    "\n",
    "                # building the corrspondences arrays of good matches\n",
    "                src_pts = np.float32([ model_images_features[i][KEYPOINT_INDEX][m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "                dst_pts = np.float32([ scene_single_model_features[j][KEYPOINT_INDEX][m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "                # Using RANSAC to estimate a robust homography. \n",
    "                # It returns the homography M and a mask for the discarded points\n",
    "                M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "                # Mask of discarded point used in visualization\n",
    "                matchesMask = mask.ravel().tolist()\n",
    "\n",
    "                # Corners of the query image\n",
    "                h,w = model_images_features[i][IMAGE_INDEX].shape[:2]\n",
    "                pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2) # myc: these are the 4 corners of the query image\n",
    "\n",
    "                # Projecting the corners into the train image\n",
    "                dst = cv2.perspectiveTransform(pts,M) # myc: you project the corners by using the homography. M is the homography          \n",
    "\n",
    "                # Drawing the bounding box\n",
    "                #scene_img = cv2.polylines(e_scenes_images_features[j][IMAGE_INDEX], [np.int32(dst)],\n",
    "                                          #True, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "                #e_results[j][i]['pos']\n",
    "                top_left_bound_box_corner = dst[0][0]\n",
    "                bottom_left_bound_box_corner = dst[1][0]\n",
    "                top_right_bound_box_corner = dst[3][0]\n",
    "                bottom_right_bound_box_corner = dst[2][0]\n",
    "                # print(top_left_bound_box_corner)\n",
    "\n",
    "\n",
    "                # compute width and height of the current bounding box\n",
    "                width_of_bounding_box = int(distance_2_points(top_left_bound_box_corner, top_right_bound_box_corner))\n",
    "                height_of_bounding_box = int(distance_2_points(top_left_bound_box_corner, bottom_left_bound_box_corner))\n",
    "\n",
    "                # I consider the current bounding box as good only if it has a shape of a rectangle, \n",
    "                # with an height > of the width, as the cereal boxes\n",
    "                if width_of_bounding_box < height_of_bounding_box:\n",
    "\n",
    "                    final_corners_of_bounding_boxes = []\n",
    "                    final_corners_of_bounding_boxes.append([top_left_bound_box_corner, bottom_right_bound_box_corner])\n",
    "                    final_corners_of_bounding_boxes_without_exceeding_dimensions = solve_exceeding_dimensions_of_bounding_boxes_in_scene(final_corners_of_bounding_boxes, e_scenes_images_features)\n",
    "\n",
    "\n",
    "                    # solve color problem with bins\n",
    "\n",
    "                    final_corners_of_bounding_boxes_after_color_problem = solve_color_problem_with_N_x_M_bins(\n",
    "                        final_corners_of_bounding_boxes_without_exceeding_dimensions, \n",
    "                        e_scenes_images_features, i, j, N=N_BINS_ON_WIDTH, M=M_BINS_ON_HEIGHT, \n",
    "                        COLOR_DIFF_IN_SINGLE_CHANNEL_TRES=COLOR_DIFF_IN_SINGLE_CHANNEL_TRES,\n",
    "                        MAX_NUM_OF_NO_GOOD_CELLS=MAX_NUM_OF_NO_GOOD_CELLS)\n",
    "\n",
    "\n",
    "\n",
    "                    # solve color problem without bins (as an unique image)\n",
    "                    #final_corners_of_bounding_boxes_after_color_problem = solve_color_problem(\n",
    "                    #    final_corners_of_bounding_boxes_without_exceeding_dimensions, e_scenes_images_features, j)\n",
    "\n",
    "                    if len(final_corners_of_bounding_boxes_after_color_problem) > 0:\n",
    "                        finding = False\n",
    "                        for [fin_top_left_corner, fin_bottom_right_corner] in final_corners_of_bounding_boxes_after_color_problem:\n",
    "                            e_results[j][i]['count'] += 1\n",
    "\n",
    "                            # Save width and height measures of the bounding box\n",
    "                            e_results[j][i]['width'] = width_of_bounding_box\n",
    "                            e_results[j][i]['height'] = height_of_bounding_box\n",
    "\n",
    "                            # Save the position of the bounding box\n",
    "                            e_results[j][i]['pos'] = (int(fin_top_left_corner[0]), int(fin_top_left_corner[1]))\n",
    "\n",
    "                    else:\n",
    "                        #print('NO CORNERS AFTER COLOR CORRECTION')\n",
    "                        for [fin_top_left_corner, fin_bottom_right_corner] in final_corners_of_bounding_boxes_without_exceeding_dimensions:\n",
    "                            scene_single_model = plot_dark_area_bounding_boxes(scene_single_model, \n",
    "                                                                               final_corners_of_bounding_boxes_without_exceeding_dimensions, \n",
    "                                                                               e_scenes_images_features, j)\n",
    "                        #plt.imshow(cv2.cvtColor(scene_single_model, cv2.COLOR_BGR2RGB))\n",
    "                        #plt.show()\n",
    "\n",
    "                    #print('COLOR CORRECTION DONE:')\n",
    "                    img_bb = plot_final_bounding_boxes(final_scene_images_with_bb[j], final_corners_of_bounding_boxes_after_color_problem, \n",
    "                                              e_scenes_images_features, j)\n",
    "                    if img_bb is not None:\n",
    "                        final_scene_images_with_bb[j] = img_bb\n",
    "\n",
    "            else:\n",
    "                #print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "                matchesMask = None\n",
    "\n",
    "            # Drawing the matches\n",
    "            draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                               singlePointColor = None, # not draw keypoints only matching lines\n",
    "                               matchesMask = matchesMask, # draw only inliers\n",
    "                               flags = 2) # not draw keypoints only lines\n",
    "            img3 = cv2.drawMatches(model_images_features[i][IMAGE_INDEX], \n",
    "                                   model_images_features[i][KEYPOINT_INDEX], \n",
    "                                   e_scenes_images_features[j][IMAGE_INDEX], \n",
    "                                   e_scenes_images_features[j][KEYPOINT_INDEX],\n",
    "                                   good, \n",
    "                                   None,  \n",
    "                                   **draw_params)\n",
    "            #plt.imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))\n",
    "            #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in scenes_to_test:\n",
    "    plt.imshow(cv2.cvtColor(final_scene_images_with_bb[j], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    print_result(e_results, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
